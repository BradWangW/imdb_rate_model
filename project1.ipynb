{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rOyOkJJA7Foy"
   },
   "source": [
    "# Machine Learning in Python - Group Project 1\n",
    "\n",
    "**Due Friday, March 10th by 16.00 pm.**\n",
    "\n",
    "*include contributors names here (such as Benjamin Chooyin, Name2, ...)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PqPpPRE37Fo0"
   },
   "source": [
    "## General Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jb4qh-pi7Fo1"
   },
   "outputs": [],
   "source": [
    "# Add any additional libraries or submodules below\n",
    "\n",
    "# Data libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plotting defaults\n",
    "plt.rcParams['figure.figsize'] = (8,5)\n",
    "plt.rcParams['figure.dpi'] = 80\n",
    "\n",
    "# sklearn modules that are necessary\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "hjs5785u7Fo1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           Ken Kwapis\n",
       "1           Ken Kwapis\n",
       "2      Ken Whittingham\n",
       "3         Bryan Gordon\n",
       "4         Greg Daniels\n",
       "            ...       \n",
       "181          Matt Sohn\n",
       "182       Jesse Peretz\n",
       "183      Jeffrey Blitz\n",
       "184       David Rogers\n",
       "185         Ken Kwapis\n",
       "Name: director, Length: 186, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "data = pd.read_csv(\"the_office.csv\")\n",
    "data = pd.DataFrame(data)\n",
    "data['director']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After making sure that all the necessary libraries or submodules are uploaded here, please follow the given skeleton to create your project report. \n",
    "- Your completed assignment must follow this structure \n",
    "- You should not add or remove any of these sections, if you feel it is necessary you may add extra subsections within each (such as *2.1. Encoding*). \n",
    "\n",
    "**Do not forget to remove the instructions for each section in the final document.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K314dGEL7Fo1"
   },
   "source": [
    "## 1. Introduction\n",
    "\n",
    "*This section should include a brief introduction to the task and the data (assume this is a report you are delivering to a client).* \n",
    "\n",
    "- If you use any additional data sources, you should introduce them here and discuss why they were included.\n",
    "\n",
    "- Briefly outline the approaches being used and the conclusions that you are able to draw."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3P6Vdzbo7Fo2"
   },
   "source": [
    "## 2. Exploratory Data Analysis and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Arg9_dYE7Fo2"
   },
   "source": [
    "*Include a detailed discussion of the data with a particular emphasis on the features of the data that are relevant for the subsequent modeling.* \n",
    "\n",
    "- Including visualizations of the data is strongly encouraged - all code and plots must also be described in the write up. \n",
    "- Think carefully about whether each plot needs to be included in your final draft - your report should include figures but they should be as focused and impactful as possible.\n",
    "\n",
    "*Additionally, this section should also implement and describe any preprocessing / feature engineering of the data.*\n",
    "\n",
    "- Specifically, this should be any code that you use to generate new columns in the data frame `d`. All of this processing is explicitly meant to occur before we split the data in to training and testing subsets. \n",
    "- Processing that will be performed as part of an sklearn pipeline can be mentioned here but should be implemented in the following section.*\n",
    "\n",
    "**All code and figures should be accompanied by text that provides an overview / context to what is being done or presented.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   season  episode   episode_name         director  \\\n",
      "0       1        1          Pilot       Ken Kwapis   \n",
      "1       1        2  Diversity Day       Ken Kwapis   \n",
      "2       1        3    Health Care  Ken Whittingham   \n",
      "3       1        4   The Alliance     Bryan Gordon   \n",
      "4       1        5     Basketball     Greg Daniels   \n",
      "\n",
      "                                        writer  imdb_rating  total_votes  \\\n",
      "0  Ricky Gervais;Stephen Merchant;Greg Daniels          7.6         3706   \n",
      "1                                   B.J. Novak          8.3         3566   \n",
      "2                             Paul Lieberstein          7.9         2983   \n",
      "3                                Michael Schur          8.1         2886   \n",
      "4                                 Greg Daniels          8.4         3179   \n",
      "\n",
      "     air_date  n_lines  n_directions  n_words  n_speak_char  \\\n",
      "0  2005-03-24      229            27     2757            15   \n",
      "1  2005-03-29      203            20     2808            12   \n",
      "2  2005-04-05      244            21     2769            13   \n",
      "3  2005-04-12      243            24     2939            14   \n",
      "4  2005-04-19      230            49     2437            18   \n",
      "\n",
      "                                          main_chars  \n",
      "0  Angela;Dwight;Jim;Kevin;Michael;Oscar;Pam;Phyl...  \n",
      "1  Angela;Dwight;Jim;Kelly;Kevin;Michael;Oscar;Pa...  \n",
      "2  Angela;Dwight;Jim;Kevin;Meredith;Michael;Oscar...  \n",
      "3  Angela;Dwight;Jim;Kevin;Meredith;Michael;Oscar...  \n",
      "4  Angela;Darryl;Dwight;Jim;Kevin;Michael;Oscar;P...  \n",
      "<bound method DataFrame.info of      season  episode      episode_name         director  \\\n",
      "0         1        1             Pilot       Ken Kwapis   \n",
      "1         1        2     Diversity Day       Ken Kwapis   \n",
      "2         1        3       Health Care  Ken Whittingham   \n",
      "3         1        4      The Alliance     Bryan Gordon   \n",
      "4         1        5        Basketball     Greg Daniels   \n",
      "..      ...      ...               ...              ...   \n",
      "181       9       19     Stairmageddon        Matt Sohn   \n",
      "182       9       20    Paper Airplane     Jesse Peretz   \n",
      "183       9       21  Livin' the Dream    Jeffrey Blitz   \n",
      "184       9       22           A.A.R.M     David Rogers   \n",
      "185       9       24            Finale       Ken Kwapis   \n",
      "\n",
      "                                          writer  imdb_rating  total_votes  \\\n",
      "0    Ricky Gervais;Stephen Merchant;Greg Daniels          7.6         3706   \n",
      "1                                     B.J. Novak          8.3         3566   \n",
      "2                               Paul Lieberstein          7.9         2983   \n",
      "3                                  Michael Schur          8.1         2886   \n",
      "4                                   Greg Daniels          8.4         3179   \n",
      "..                                           ...          ...          ...   \n",
      "181                                 Dan Sterling          8.0         1484   \n",
      "182          Halsted Sullivan;Warren Lieberstein          8.0         1482   \n",
      "183                        Nicki Schwartz-Wright          8.9         2041   \n",
      "184                              Brent Forrester          9.3         2860   \n",
      "185                                 Greg Daniels          9.7         7934   \n",
      "\n",
      "       air_date  n_lines  n_directions  n_words  n_speak_char  \\\n",
      "0    2005-03-24      229            27     2757            15   \n",
      "1    2005-03-29      203            20     2808            12   \n",
      "2    2005-04-05      244            21     2769            13   \n",
      "3    2005-04-12      243            24     2939            14   \n",
      "4    2005-04-19      230            49     2437            18   \n",
      "..          ...      ...           ...      ...           ...   \n",
      "181  2013-04-11      273            59     2965            24   \n",
      "182  2013-04-25      234            48     2564            27   \n",
      "183  2013-05-02      382            33     4333            20   \n",
      "184  2013-05-09      501            54     4965            30   \n",
      "185  2013-05-16      522           107     5960            54   \n",
      "\n",
      "                                            main_chars  \n",
      "0    Angela;Dwight;Jim;Kevin;Michael;Oscar;Pam;Phyl...  \n",
      "1    Angela;Dwight;Jim;Kelly;Kevin;Michael;Oscar;Pa...  \n",
      "2    Angela;Dwight;Jim;Kevin;Meredith;Michael;Oscar...  \n",
      "3    Angela;Dwight;Jim;Kevin;Meredith;Michael;Oscar...  \n",
      "4    Angela;Darryl;Dwight;Jim;Kevin;Michael;Oscar;P...  \n",
      "..                                                 ...  \n",
      "181  Andy;Angela;Creed;Dwight;Erin;Jim;Kevin;Meredi...  \n",
      "182  Andy;Angela;Creed;Darryl;Dwight;Erin;Jim;Kevin...  \n",
      "183  Andy;Angela;Creed;Darryl;Dwight;Erin;Jim;Kevin...  \n",
      "184  Andy;Angela;Creed;Darryl;Dwight;Erin;Jim;Kevin...  \n",
      "185  Andy;Angela;Creed;Darryl;Dwight;Erin;Jim;Kelly...  \n",
      "\n",
      "[186 rows x 13 columns]>\n",
      "           season     episode  imdb_rating  total_votes     n_lines  \\\n",
      "count  186.000000  186.000000   186.000000   186.000000  186.000000   \n",
      "mean     5.462366   12.478495     8.250538  2129.543011  296.397849   \n",
      "std      2.398464    7.233710     0.535168   790.787586   81.998568   \n",
      "min      1.000000    1.000000     6.700000  1393.000000  131.000000   \n",
      "25%      3.000000    6.000000     7.900000  1628.500000  255.250000   \n",
      "50%      6.000000   12.000000     8.200000  1954.000000  281.000000   \n",
      "75%      7.750000   18.000000     8.600000  2385.000000  314.500000   \n",
      "max      9.000000   28.000000     9.700000  7934.000000  625.000000   \n",
      "\n",
      "       n_directions      n_words  n_speak_char  \n",
      "count    186.000000   186.000000    186.000000  \n",
      "mean      50.150538  3053.510753     20.693548  \n",
      "std       23.941797   799.271717      5.092407  \n",
      "min       11.000000  1098.000000     12.000000  \n",
      "25%       34.000000  2670.250000     17.000000  \n",
      "50%       46.000000  2872.500000     20.000000  \n",
      "75%       60.000000  3141.000000     23.000000  \n",
      "max      166.000000  6076.000000     54.000000  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/seaborn/axisgrid.py:2076: UserWarning: The `size` parameter has been renamed to `height`; please update your code.\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Many of these pairplots contain little information but there are some interesting trends. Season 8 was unpopular.\\nThe ratings are normally distributed, The number of lines and number of words are strongly correlated so we may not need both \\nvariables. Total votes and imbd rating look like they could have some qaudratic correlation \\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Exploratory data analysis to get a sense of the variables\n",
    "print(data.head())\n",
    "print(data.info)\n",
    "print(data.describe())\n",
    "\n",
    "#The data contains 186 episodes with a mean ammount of votes 2130 per episode and a mean rating of 8.25. \n",
    "sns.pairplot(data, size = 50)\n",
    "'''Many of these pairplots contain little information but there are some interesting trends. Season 8 was unpopular.\n",
    "The ratings are normally distributed, The number of lines and number of words are strongly correlated so we may not need both \n",
    "variables. Total votes and imbd rating look like they could have some qaudratic correlation \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1  2  3  4  5  6  7  8  9\n",
      "0    1  0  0  0  0  0  0  0  0\n",
      "1    1  0  0  0  0  0  0  0  0\n",
      "2    1  0  0  0  0  0  0  0  0\n",
      "3    1  0  0  0  0  0  0  0  0\n",
      "4    1  0  0  0  0  0  0  0  0\n",
      "..  .. .. .. .. .. .. .. .. ..\n",
      "181  0  0  0  0  0  0  0  0  1\n",
      "182  0  0  0  0  0  0  0  0  1\n",
      "183  0  0  0  0  0  0  0  0  1\n",
      "184  0  0  0  0  0  0  0  0  1\n",
      "185  0  0  0  0  0  0  0  0  1\n",
      "\n",
      "[186 rows x 9 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_67/2185222898.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.season[i] = str(data.season[i])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Attempt to one hot encode main characters\\n#for i in range(0,len(data.main_chars)):\\n#   data.main_chars[i] = data.main_chars[i].split(\\';\\')\\nmylist = []\\nfor i in range(0,len(data.main_chars)):\\n    for j in range(0,len(data.main_chars[i])):\\n        mylist.append(data.main_chars[i][j])\\nmylist= [set(mylist)]\\nprint(mylist)\\n\\n\\n\\n#encoded = pd.Data_Frame(mlb.fit_transform([spaced_data[\"main_chars\"]]), columns= mlb.classes_)\\n#result = pd.concat([data[\\'main_chars\\'], encoded], axis=1)\\n#result\\n\\n'"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Encoding some of the variables as numerical values instead of strings\n",
    "\n",
    "\n",
    "#Onehot Encoding the director column\n",
    "\n",
    "#!!Run these lines only once to convert strings to a list\n",
    "#for i in range(0,len(data.director)):\n",
    "#   data.director[i] = [data.director[i]]\n",
    "for i in range(0,len(data.season)):\n",
    "   data.season[i] = str(data.season[i])\n",
    "\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "encoded_directors = pd.DataFrame(mlb.fit_transform(data['director']), columns= mlb.classes_)\n",
    "pd.set_option('display.max_columns', None)\n",
    "encoded_directors\n",
    "\n",
    "encoded_seasons = pd.DataFrame(mlb.fit_transform(data['season']), columns= mlb.classes_)\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(encoded_seasons)\n",
    "\n",
    "data.drop()\n",
    "\n",
    "'''Attempt to one hot encode main characters\n",
    "#for i in range(0,len(data.main_chars)):\n",
    "#   data.main_chars[i] = data.main_chars[i].split(';')\n",
    "mylist = []\n",
    "for i in range(0,len(data.main_chars)):\n",
    "    for j in range(0,len(data.main_chars[i])):\n",
    "        mylist.append(data.main_chars[i][j])\n",
    "mylist= [set(mylist)]\n",
    "print(mylist)\n",
    "\n",
    "\n",
    "\n",
    "#encoded = pd.Data_Frame(mlb.fit_transform([spaced_data[\"main_chars\"]]), columns= mlb.classes_)\n",
    "#result = pd.concat([data['main_chars'], encoded], axis=1)\n",
    "#result\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ad7J-Yw67Fo3"
   },
   "source": [
    "## 3. Model Fitting and Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EXdvOaZs7Fo3"
   },
   "source": [
    "*In this section you should detail your choice of model and describe the process used to refine and fit that model.*\n",
    "\n",
    "- You are strongly encouraged to explore many different modeling methods (e.g. linear regression, regression trees, lasso, etc.) but you should not include a detailed narrative of all of these attempts. \n",
    "- At most this section should mention the methods explored and why they were rejected - most of your effort should go into describing the model you are using and your process for tuning and validatin it.\n",
    "\n",
    "*For example if you considered a linear regression model, a classification tree, and a lasso model and ultimately settled on the linear regression approach then you should mention that other two approaches were tried but do not include any of the code or any in depth discussion of these models beyond why they were rejected. This section should then detail is the development of the linear regression model in terms of features used, interactions considered, and any additional tuning and validation which ultimately led to your final model.* \n",
    "\n",
    "**This section should also include the full implementation of your final model, including all necessary validation. As with figures, any included code must also be addressed in the text of the document.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "edQVULLU7Fo3"
   },
   "source": [
    "## 4. Discussion and Conclusions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fi0yKPrQ7Fo4"
   },
   "source": [
    "*In this section you should provide a general overview of **your final model**, its **performance**, and **reliability**.* \n",
    "\n",
    "- You should discuss what the implications of your model are in terms of the included features, predictive performance, and anything else you think is relevant.\n",
    "\n",
    "- This should be written with a target audience of a NBC Universal executive who is with the show and university level mathematics but not necessarily someone who has taken a postgraduate statistical modeling course. \n",
    "\n",
    "- Your goal should be to convince this audience that your model is both accurate and useful.\n",
    "\n",
    "- Finally, you should include concrete recommendations on what NBC Universal should do to make their reunion episode a popular as possible.\n",
    "\n",
    "**Keep in mind that a negative result, i.e. a model that does not work well predictively, but that is well explained and justified in terms of why it failed will likely receive higher marks than a model with strong predictive performance but with poor or incorrect explanations / justifications.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. References\n",
    "\n",
    "*In this section, you should present a list of external sources (except the course materials) that you used during the project, if any*\n",
    "\n",
    "- Additional data sources can be cited here, in addition to related python documentations, any other webpage sources that you benefited from"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "project1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
